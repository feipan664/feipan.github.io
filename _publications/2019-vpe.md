---
title: "Variational Prototyping-Encoder: One-Shot Learning with Prototypical Images"
collection: publications
permalink: /publications/2019-vpe
date: 2019-06-16
venue: "IEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR 2019)"
citation: "Junsik Kim, Tae-Hyun Oh, Seokju Lee, <b>Fei Pan</b>, In So Kweon. <i>IEEE Conference on Computer Vision and Pattern Recognition 2019</i>. <b>CVPR 2019</b>."
---

[[Paper]](https://arxiv.org/pdf/1904.08482.pdf) [[Code]](https://github.com/mibastro/VPE)

## Abstract
In daily life, graphic symbols, such as traffic signs and brand logos, are ubiquitously utilized around us due to its intuitive expression beyond language boundary. We tackle an open-set graphic symbol recognition problem by one-shot classification with prototypical images as a single training example for each novel class. We take an approach to learn a generalizable embedding space for novel tasks. We propose a new approach called variational prototyping-encoder (VPE) that learns the image translation task from real-world input images to their corresponding prototypical images as a meta-task. As a result, VPE learns image similarity as well as prototypical concepts which differs from widely used metric learning based approaches. Our experiments with diverse datasets demonstrate that the proposed VPE performs favorably against competing metric learning based one-shot methods. Also, our qualitative analyses show that our meta-task induces an effective embedding space suitable for unseen data representation.